{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPsnR886I0-3"
   },
   "source": [
    "# chip-seq analysis\n",
    "\n",
    "cut up the genome into sequences. align them to the genome. look at distribution.\n",
    "\n",
    "## macs2 - peak caller\n",
    "\n",
    "output is bedfile. has chromosome, start, strand information. this is where we come in.\n",
    "\n",
    "We love [ENCODE](https://www.encodeproject.org). Encyclopedia of DNA Elements. This has lots of non-coding DNA elements (which is often regulatory).\n",
    "\n",
    "How do we know if a DNA region is regulatory? Just because a protein binds to it does not necessarily mean it is biologically meaningful. \n",
    "\n",
    "We want to narrow down to TF ChIP-seq experiments.\n",
    "\n",
    "For example, https://www.encodeproject.org/experiments/ENCSR000DRZ/\n",
    "\n",
    "- BAM file has alignements.\n",
    "- bigWig allows you to visualize data on genome browser (nice for presentations). Shush and Amber have been doing this with ChIP-seq peaks.\n",
    "\n",
    "We are most interested in BED files. Want to use merged data (replicates 1,2 for example). Go with \"conservative IDR thresholded peaks\" (though there are many more).\n",
    "\n",
    "https://www.encodeproject.org/chip-seq/transcription_factor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reference genome(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p references\n",
    "cd references\n",
    "if [ ! -f hg19.fa ]; then\n",
    "    curl -fL https://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz | gunzip > hg19.fa\n",
    "fi\n",
    "if [ ! -f hg38.fa ]; then\n",
    "    curl -fL https://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip > hg38.fa\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process positives and negative peaks\n",
    "\n",
    "Go from BED file to one-hot encoded output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import chipseq_utils\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "datasets_dir = Path(\"datasets\")\n",
    "references_dir = Path(\"references\")\n",
    "reference_hg19 = references_dir / \"hg19.fa\"\n",
    "reference_hg38 = references_dir / \"hg38.fa\"\n",
    "\n",
    "assert reference_hg19.exists()\n",
    "assert reference_hg38.exists()\n",
    "\n",
    "dataset = namedtuple(\n",
    "    \"Dataset\",\n",
    "    [\n",
    "        \"path\",\n",
    "        \"positive_encode_url\",\n",
    "        \"positive_bed_url\",\n",
    "        \"negative_encode_url\",\n",
    "        \"negative_bed_url\",\n",
    "        \"reference_genome_fasta\",\n",
    "        \"summary\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "datasets = [\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg19\" / \"ENCSR000DRZ_ENCSR000EMT\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DRZ/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF963PJY/@@download/ENCFF963PJY.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EMT/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF097LEF/@@download/ENCFF097LEF.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg19,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human GM12878.\n",
    "Negative reads are from DNase-seq on human GM12878.\n",
    "Reference is hg19.\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR000DZN_ENCSR000EMT\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DZN/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF796WRU/@@download/ENCFF796WRU.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EMT/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF195QAV/@@download/ENCFF195QAV.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human GM12878.\n",
    "Negative reads are from DNase-seq on human GM12878.\n",
    "Reference is GRCh38 (hg38).\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR000AKB_ENCSR000EMT\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000AKB/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF017XLW/@@download/ENCFF017XLW.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EMT/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF195QAV/@@download/ENCFF195QAV.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human GM12878.\n",
    "Negative reads are from DNase-seq on human GM12878.\n",
    "Reference is GRCh38 (hg38).\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg19\" / \"ENCSR000AKB_ENCSR000EMT\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000AKB/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF096AKZ/@@download/ENCFF096AKZ.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EMT/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF097LEF/@@download/ENCFF097LEF.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg19,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human GM12878.\n",
    "Negative reads are from DNase-seq on human GM12878.\n",
    "Reference is hg19.\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR000DKV_ENCSR000EMT\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DKV/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF258AFQ/@@download/ENCFF258AFQ.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EMT/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF195QAV/@@download/ENCFF195QAV.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human GM12878.\n",
    "Negative reads are from DNase-seq on human GM12878.\n",
    "Reference is GRCh38 (hg38).\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR560BUE_ENCSR000EPH\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR560BUE/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF203DXT/@@download/ENCFF203DXT.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EPH/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF886OJN/@@download/ENCFF886OJN.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human MCF-7.\n",
    "Negative reads are from DNase-seq on human MCF-7 treated with estradiol at 100nM for 0 hour (control).\n",
    "Reference is GRCh38 (hg38).\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg19\" / \"ENCSR560BUE_ENCSR000EPH\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR560BUE/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF990LUT/@@download/ENCFF990LUT.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EPH/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF846DFL/@@download/ENCFF846DFL.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg19,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human MCF-7.\n",
    "Negative reads are from DNase-seq on human MCF-7 treated with estradiol at 100nM for 0 hour (control).\n",
    "Reference is hg19.\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR000DWH_ENCSR000EPH\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DWH/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF742FBX/@@download/ENCFF742FBX.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EPH/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF886OJN/@@download/ENCFF886OJN.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human MCF-7.\n",
    "Negative reads are from DNase-seq on human MCF-7 treated with estradiol at 100nM for 0 hour (control).\n",
    "Reference is GRCH38 (hg38).\n",
    "\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg19\" / \"ENCSR000DWH_ENCSR000EPH\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DWH/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF720OXG/@@download/ENCFF720OXG.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EPH/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF846DFL/@@download/ENCFF846DFL.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg19,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human MCF-7.\n",
    "Negative reads are from DNase-seq on human MCF-7 treated with estradiol at 100nM for 0 hour (control).\n",
    "Reference is hg19.\"\"\",\n",
    "    ),\n",
    "    dataset(\n",
    "        path=datasets_dir / \"CTCF\" / \"hg38\" / \"ENCSR000DMV_ENCSR000EPH\",\n",
    "        positive_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000DMV/\",\n",
    "        positive_bed_url=\"https://www.encodeproject.org/files/ENCFF663NFF/@@download/ENCFF663NFF.bed.gz\",\n",
    "        negative_encode_url=\"https://www.encodeproject.org/experiments/ENCSR000EPH/\",\n",
    "        negative_bed_url=\"https://www.encodeproject.org/files/ENCFF886OJN/@@download/ENCFF886OJN.bed.gz\",\n",
    "        reference_genome_fasta=reference_hg38,\n",
    "        summary=\"\"\"\\\n",
    "Positive reads are from CTCF ChIP-seq on human MCF-7.\n",
    "Negative reads are from DNase-seq on human MCF-7 treated with estradiol at 100nM for 0 hour (control).\n",
    "Reference is GRCH38 (hg38).\n",
    "\"\"\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "max_read_length = 250\n",
    "new_read_length = 200\n",
    "alphabet = \"ACGT\"\n",
    "nonsense_letters = \"N\"\n",
    "hdf5_path = Path(\"chip-seq-datasets.h5\")\n",
    "\n",
    "for d in datasets:\n",
    "    positive_output, negative_output = chipseq_utils.bed_to_fasta_to_one_hot(\n",
    "        dataset_dir=d.path,\n",
    "        positive_bed_url=d.positive_bed_url,\n",
    "        negative_bed_url=d.negative_bed_url,\n",
    "        reference_genome_fasta=d.reference_genome_fasta,\n",
    "        max_read_length=max_read_length,\n",
    "        new_read_length=new_read_length,\n",
    "        alphabet=alphabet,\n",
    "        nonsense_letters=nonsense_letters,\n",
    "    )\n",
    "\n",
    "    # Sample negatives so GC content is similar to positives.\n",
    "    print(\"sampling negatives for similar GC content...\")\n",
    "    positive_gc_content = positive_output.one_hot[:, :, 1:3].any(-1).mean(1)\n",
    "    negative_gc_content = negative_output.one_hot[:, :, 1:3].any(-1).mean(1)\n",
    "    size = min(positive_gc_content.shape[0], negative_gc_content.shape[0])\n",
    "    inds = chipseq_utils.sample_b_matched_to_a(\n",
    "        positive_gc_content, negative_gc_content, size=size, seed=42\n",
    "    )\n",
    "\n",
    "    # Save to hdf5.\n",
    "    print(\"saving to hdf5 ...\")\n",
    "    features = np.concatenate((positive_output.one_hot, negative_output.one_hot[inds]))\n",
    "    n_positives = positive_output.one_hot.shape[0]\n",
    "    n_negatives = inds.shape[0]\n",
    "    n_total = n_positives + n_negatives\n",
    "    print(n_total, \"total sequences\")\n",
    "    labels = np.zeros(n_total, dtype=np.uint8)\n",
    "    labels[:n_positives] = 1\n",
    "    dataset_features = str(d.path / \"features\")\n",
    "    dataset_labels = str(d.path / \"labels\")\n",
    "    print(f\"features dataset  {dataset_features}\")\n",
    "    print(f\"labels dataset    {dataset_labels}\")\n",
    "\n",
    "    with h5py.File(hdf5_path, mode=\"a\") as f:\n",
    "        f.create_dataset(dataset_features, data=features, compression=\"gzip\")\n",
    "        f.create_dataset(dataset_labels, data=labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chipseq_utils\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = \"/datasets/CTCF/hg38/ENCSR000AKB_ENCSR000EMT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"chip-seq-datasets.h5\", \"r\") as f:\n",
    "    features = f[f\"{dset}/features\"][:]\n",
    "    labels = f[f\"{dset}/labels\"][:]\n",
    "\n",
    "print(\"features.shape\", features.shape)\n",
    "print(\"labels.shape\", labels.shape)\n",
    "n_samples = features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = chipseq_utils.get_splits(n_samples, [0.8, 0.1, 0.1], seed=42)\n",
    "\n",
    "x_train = features[train]\n",
    "y_train = labels[train]\n",
    "\n",
    "x_val = features[val]\n",
    "y_val = labels[val]\n",
    "\n",
    "x_test = features[test]\n",
    "y_test = labels[test]\n",
    "\n",
    "print(\"train shapes\", x_train.shape, y_train.shape)\n",
    "print(\"val shapes\", x_val.shape, y_val.shape)\n",
    "print(\"test shapes\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    pool1: int, pool2: int, n_classes: int, input_shape: (int, int), batch_size: int = None\n",
    ") -> tfk.Sequential:\n",
    "    \"\"\"Return a Model object with two convolutional layers, a\n",
    "    fully-connected hidden layer, and output. Sigmoid activation is\n",
    "    applied to logits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pool1 : int\n",
    "        Size of pooling window in the max-pooling operation after the first\n",
    "        convolution.\n",
    "    pool2 : int\n",
    "        Size of pooling window in the max-pooling operation after the second\n",
    "        convolution.\n",
    "    n_classes : int\n",
    "        Number of output units.\n",
    "    batch_size : int\n",
    "        Batch size of input. If `None`, batch size can be variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Instance of `tf.keras.Sequential`. This model is not compiled.\n",
    "    \"\"\"\n",
    "    if pool1 * pool2 != 100:\n",
    "        raise ValueError(\"product of pool sizes must be 100\")\n",
    "    l2_reg = tfk.regularizers.l2(1e-6)\n",
    "    return tfk.Sequential(\n",
    "        [\n",
    "            tfkl.Input(shape=input_shape, batch_size=batch_size),\n",
    "            # layer 1\n",
    "            tfkl.Conv1D(\n",
    "                filters=30,\n",
    "                kernel_size=19,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=l2_reg,\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.MaxPool1D(pool_size=pool1, strides=pool1),\n",
    "            tfkl.Dropout(0.1),\n",
    "            # layer 2\n",
    "            tfkl.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=5,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=l2_reg,\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.MaxPool1D(pool_size=pool2, strides=pool2),\n",
    "            tfkl.Dropout(0.1),\n",
    "            # layer 3\n",
    "            tfkl.Flatten(),\n",
    "            tfkl.Dense(\n",
    "                units=512, activation=None, use_bias=None, kernel_regularizer=l2_reg\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.Dropout(0.5),\n",
    "            # layer 4 (output). do not use activation (ie linear activation) so we can inspect\n",
    "            # the logits later.\n",
    "            tfkl.Dense(\n",
    "                units=n_classes,\n",
    "                activation=None,\n",
    "                use_bias=True,\n",
    "                kernel_initializer=tfk.initializers.GlorotNormal(),\n",
    "                bias_initializer=tfk.initializers.Zeros(),\n",
    "                name=\"logits\",\n",
    "            ),\n",
    "            tfkl.Activation(tf.nn.sigmoid, name=\"predictions\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "model = get_model(25, 4, n_classes=n_classes, input_shape=features.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tfk.metrics.AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "    tfk.metrics.AUC(curve=\"PR\", name=\"aupr\"),  # precision-recall\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tfk.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tfk.callbacks.EarlyStopping(\n",
    "        monitor=\"val_aupr\",\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        restore_best_weights=False,\n",
    "    ),\n",
    "    tfk.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_aupr\",\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "    ),\n",
    "]\n",
    "# train\n",
    "history: tfk.callbacks.History = model.fit(\n",
    "    x=x_train,\n",
    "    y=tf.one_hot(y_train, n_classes),\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_val, tf.one_hot(y_val, n_classes)),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --timestamping https://www.dropbox.com/s/ha1sryrxfhx7ex7/JASPAR_CORE_2016_vertebrates.meme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tomtom analysis like in representation learning paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tfomics\n",
    "import tfomics.impress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for comparison between motifs and filters for one model.\n",
    "meme_entry = namedtuple(\n",
    "    \"meme_entry\",\n",
    "    \"match_fraction match_any filter_match filter_qvalue min_qvalue num_counts\",\n",
    ")\n",
    "_ = model.evaluate(x_test, y_test)\n",
    "\n",
    "# layers: (0)conv -> (1)batchnorm -> (2)relu\n",
    "W = tfomics.moana.filter_activations(\n",
    "    x_test=x_test, model=model, layer=2, window=20, threshold=0.5\n",
    ")\n",
    "\n",
    "# Create meme file\n",
    "W_clipped = tfomics.moana.clip_filters(W, threshold=0.5, pad=3)\n",
    "meme_file = save_dir / \"filters.meme\"\n",
    "tfomics.moana.meme_generate(W_clipped, output_file=meme_file, prefix=\"filter\")\n",
    "print(\"++ saved motifs to\", meme_file)\n",
    "\n",
    "# Use tomtom to determine which motifs our filters are similar to.\n",
    "print(\"++ running tomtom\")\n",
    "output_path = \"filters\"\n",
    "jaspar_path = \"JASPAR_CORE_2016_vertebrates.meme\"\n",
    "args = [\n",
    "    \"tomtom\",\n",
    "    \"-thresh\",\n",
    "    \"0.5\",\n",
    "    \"-dist\",\n",
    "    \"pearson\",\n",
    "    \"-evalue\",\n",
    "    \"-oc\",\n",
    "    output_path,\n",
    "    meme_file,\n",
    "    jaspar_path,\n",
    "]\n",
    "ret = subprocess.run(args, check=True)\n",
    "\n",
    "    # See which motifs the filters are similar to.\n",
    "num_filters = tfomics.moana.count_meme_entries(meme_file)\n",
    "out = tfomics.evaluate.motif_comparison_synthetic_dataset(\n",
    "    Path(output_path) / \"tomtom.tsv\", num_filters=num_filters\n",
    ")\n",
    "this_meme_entry = meme_entry(*out)\n",
    "\n",
    "# Plot logos with motif names.\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "tfomics.impress.plot_filters(W, fig, num_cols=6, names=this_meme_entry.filter_match, fontsize=14)\n",
    "fig.suptitle(f\"filters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch space below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match by GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "positive_gc_content = positive_output.one_hot[:, :, 1:3].any(-1).mean(1)\n",
    "axes[0].hist(positive_gc_content, bins=25, range=(0, 1))\n",
    "axes[0].set_title(\"GC in positives\")\n",
    "\n",
    "negative_gc_content = negative_output.one_hot[:, :, 1:3].any(-1).mean(1)\n",
    "axes[1].hist(negative_gc_content, bins=25, range=(0, 1))\n",
    "axes[1].set_title(\"GC negatives\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = chipseq_utils.sample_b_matched_to_a(positive_gc_content, negative_gc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10, 5))\n",
    "axes = axes.ravel()\n",
    "axes[0].hist(positive_gc_content, bins=25, range=(0, 1))\n",
    "axes[0].set_title(\"GC in positives\")\n",
    "\n",
    "axes[1].hist(negative_gc_content[inds], bins=25, range=(0, 1))\n",
    "axes[1].set_title(f\"GC in sampled negatives\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "features = np.concatenate((positive_output.one_hot, negative_output.one_hot[inds]))\n",
    "\n",
    "n_positives = positive_output.one_hot.shape[0]\n",
    "n_negatives = inds.shape[0]\n",
    "n_total = n_positives + n_negatives\n",
    "print(n_total_sequences, \"total sequences\")\n",
    "\n",
    "labels = np.zeros(n_total, dtype=np.uint8)\n",
    "labels[:n_positives] = 1\n",
    "\n",
    "dataset_features = str(dataset_dir / \"features\")\n",
    "dataset_labels = str(dataset_dir / \"labels\")\n",
    "print(f\"features dataset  {dataset_features}\")\n",
    "print(f\"labels dataset    {dataset_labels}\")\n",
    "\n",
    "hdf5_path = Path(\"chip-seq-datasets.h5\")\n",
    "\n",
    "with h5py.File(hdf5_path, mode=\"w\") as f:\n",
    "    f.create_dataset(dataset_features, data=features, compression=\"gzip\")\n",
    "    f.create_dataset(dataset_labels, data=labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get positive peak data\n",
    "\n",
    "- Stamatoyannopoulos - Univ of Washington\n",
    "- CTCF ChIP-seq on human GM12878\n",
    "- https://www.encodeproject.org/experiments/ENCSR000DRZ/\n",
    "- conservative IDR thresholded peaks  1,2  hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bed_file_url = (\n",
    "    \"https://www.encodeproject.org/files/ENCFF963PJY/@@download/ENCFF963PJY.bed.gz\"\n",
    ")\n",
    "input_bed_file = datasets / \"CTCF\" / \"Stamatoyannopoulos\" / \"positive_peaks.bed.gz\"\n",
    "input_bed_file.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not input_bed_file.exists():\n",
    "    print(\"downloading...\")\n",
    "    _ = chipseq_utils.download(\n",
    "        url=input_bed_file_url,\n",
    "        output_path=input_bed_file,\n",
    "        force=True,\n",
    "    )\n",
    "\n",
    "output = chipseq_utils._bed_to_fasta_to_onehot(\n",
    "    bed_file=input_bed_file,\n",
    "    max_read_length=max_read_length,\n",
    "    new_read_length=constant_read_length,\n",
    "    reference_genome_fasta=reference_genome_fasta,\n",
    "    alphabet=alphabet,\n",
    "    nonsense_letters=nonsense_letters,\n",
    "    bedtools_exe=\"bedtools\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get negative peak data\n",
    "\n",
    "- Stamatoyannopoulos - Univ of Washington\n",
    "- DNase-seq on human GM12878\n",
    "- https://www.encodeproject.org/experiments/ENCSR000EMT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bed_file_url = (\n",
    "    \"https://www.encodeproject.org/files/ENCFF097LEF/@@download/ENCFF097LEF.bed.gz\"\n",
    ")\n",
    "input_bed_file = datasets / \"CTCF\" / \"Stamatoyannopoulos\" / \"negative_peaks.bed.gz\"\n",
    "input_bed_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not input_bed_file.exists():\n",
    "    print(\"downloading...\")\n",
    "    _ = chipseq_utils.download(\n",
    "        url=input_bed_file_url,\n",
    "        output_path=input_bed_file,\n",
    "        force=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_file_nonintersect = chipseq_utils.add_str_before_suffixes(\n",
    "    input_bed_file, \"_nonintersect\"\n",
    ")\n",
    "\n",
    "_ = chipseq_utils.bedtools_intersect(\n",
    "    a=input_bed_file,\n",
    "    b=output.bed_file_filtered,\n",
    "    output_bedfile=input_file_file_nonintersect,\n",
    "    write_a=True,\n",
    "    invert_match=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = chipseq_utils._bed_to_fasta_to_onehot(\n",
    "    bed_file=input_file_file_nonintersect,\n",
    "    max_read_length=max_read_length,\n",
    "    new_read_length=constant_read_length,\n",
    "    reference_genome_fasta=reference_genome_fasta,\n",
    "    alphabet=alphabet,\n",
    "    nonsense_letters=nonsense_letters,\n",
    "    bedtools_exe=\"bedtools\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download ChIP-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# save all things here\n",
    "data_dir = Path(\"datasets\") / \"CTCF_Stamatoyannopoulos\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chipseq_bedfile = data_dir / \"positive_peaks.bed.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-I8CI95kI7Ez",
    "outputId": "9464e67c-b521-47d7-9e54-8f173441de33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stamatoyannopoulos - Univ of Washington\n",
    "# CTCF ChIP-seq on human GM12878\n",
    "# https://www.encodeproject.org/experiments/ENCSR000DRZ/\n",
    "# conservative IDR thresholded peaks  1,2  hg19\n",
    "!wget -O $chipseq_bedfile https://www.encodeproject.org/files/ENCFF963PJY/@@download/ENCFF963PJY.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNGptPAwPCn6",
    "outputId": "5c4da922-4a24-497d-a8e3-07718e7058bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect ChIP-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsO8KpIzPCgg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(chipseq_bedfile, delimiter=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxBtdYXmPCXI"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = df.loc[:, 2] - df.loc[:, 1]\n",
    "plt.hist(lengths, bins=20)\n",
    "plt.title(\"Distribution of peak length in ChIP-seq data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter ChIP-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chipseq_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(chipseq_bedfile, delimiter=\"\\t\", header=None)\n",
    "df = chipseq_utils.filter_bed_by_max_length(df, max_length=250)\n",
    "df = chipseq_utils.transform_bed_to_constant_size(df, new_length=250)\n",
    "\n",
    "chipseq_bedfile_filtered = chipseq_utils.add_str_before_suffixes(\n",
    "    chipseq_bedfile, string=\"_filtered\"\n",
    ")\n",
    "df.to_csv(chipseq_bedfile_filtered, sep=\"\\t\", index=False, header=False)\n",
    "print(f\"Saved to '{chipseq_bedfile_filtered}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## something something fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get reference genome\n",
    "\n",
    "In this case, reference genome is in `.2bit` format, so we must convert to fasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get reference genome\n",
    "!wget -N -nv --show-progress https://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yls39buqRPcQ",
    "outputId": "16b65b02-43e3-452b-fd49-d960d811ec62",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get program that converts twobit to fasta format\n",
    "!wget -N -nv --show-progress http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
    "!chmod +x twoBitToFa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert 2bit for fasta.\n",
    "reference_fasta = \"hg19.fa\"\n",
    "process = chipseq_utils.twobit_to_fasta(\"hg19.2bit\", reference_fasta)\n",
    "print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3N9rLb-zTJZZ",
    "outputId": "c6699d39-031b-4f3a-d8c0-e3f974dd9f27"
   },
   "outputs": [],
   "source": [
    "# Install bedtools if the program is not found.\n",
    "![[ $(command -v bedtools) ]] || sudo apt-get install --yes --quiet bedtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fasta file from the bedfile.\n",
    "\n",
    "chipseq_fasta = chipseq_utils.add_str_before_suffixes(\n",
    "    chipseq_bedfile_filtered, \"_hg19\"\n",
    ").with_suffix(\".fa\")\n",
    "\n",
    "process = chipseq_utils.bedtools_getfasta(\n",
    "    input_fasta=reference_fasta,\n",
    "    output_fasta=chipseq_fasta,\n",
    "    bed_file=chipseq_bedfile_filtered,\n",
    "    force_strandedness=True,\n",
    ")\n",
    "print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo-YX4y7UP_p",
    "outputId": "b282e052-01d8-4063-b1e4-1bc2075b0ca7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n 4 $chipseq_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sequences\n",
    "descriptions, sequences = chipseq_utils.parse_fasta(chipseq_fasta)\n",
    "\n",
    "# filter out nonsense\n",
    "nonsense = chipseq_utils.get_nonsense_sequence_mask(sequences, nonsense_letters=\"N\")\n",
    "print(f\"Found {nonsense.sum()} sequences with nonsense letters\")\n",
    "descriptions = descriptions[~nonsense]\n",
    "sequences = sequences[~nonsense]\n",
    "\n",
    "# one-hot encode\n",
    "sequences_onehot = chipseq_utils.one_hot(sequences)\n",
    "print(\"Shape of one-hot encoded data:\", sequences_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get GC content per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This assumes that GC are in slices 1:3 of the one-hot encoded data.\n",
    "# shape of this is (n_sequences,)\n",
    "gc_content_pos = sequences_onehot[:, :, 1:3].any(-1).mean(1)\n",
    "\n",
    "plt.hist(gc_content_pos, bins=25, range=(0, 1))\n",
    "plt.title(\"Histogram of GC content among positive sequences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create negative data\n",
    "\n",
    "Get non-overlap between positive peaks and negative peaks.\n",
    "\n",
    "Negative labels sampled from same distribution but without the pattern we are interested in. We will use DNAseq for the same cell-type as our negative control. This gives us accessible regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_chipseq_bedfile = data_dir / \"negative_peaks.bed.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stamatoyannopoulos - Univ of Washington\n",
    "# DNase-seq on human GM12878\n",
    "# https://www.encodeproject.org/experiments/ENCSR000EMT/\n",
    "!wget -O $neg_chipseq_bedfile https://www.encodeproject.org/files/ENCFF097LEF/@@download/ENCFF097LEF.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_chipseq_bedfile_nonoverlap = data_dir / \"neg_nonoverlap.bed.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedtools intersect -v -wa -a $neg_chipseq_bedfile -b $chipseq_bedfile_filtered | gzip > $neg_chipseq_bedfile_nonoverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "process = chipseq_utils.bedtools_intersect(\n",
    "    neg_chipseq_bedfile,\n",
    "    chipseq_bedfile_filtered,\n",
    "    output_bedfile=\"output.bed\",\n",
    "    write_a=True,\n",
    "    invert_match=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# do the same processing as above for negative peaks. in the end, you want\n",
    "# one-hot representation of the negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(neg_chipseq_bedfile_nonoverlap, delimiter=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = df.loc[:, 2] - df.loc[:, 1]\n",
    "plt.hist(lengths, bins=20)\n",
    "plt.title(\"Distribution of peak length in negative reads\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(neg_chipseq_bedfile_nonoverlap, delimiter=\"\\t\", header=None)\n",
    "df = chipseq_utils.filter_bed_by_max_length(df, max_length=250)\n",
    "df = chipseq_utils.transform_bed_to_constant_size(df, new_length=250)\n",
    "\n",
    "neg_chipseq_bedfile_nonoverlap_filtered = chipseq_utils.add_str_before_suffixes(\n",
    "    neg_chipseq_bedfile_nonoverlap, string=\"_filtered\"\n",
    ")\n",
    "df.to_csv(neg_chipseq_bedfile_nonoverlap_filtered, sep=\"\\t\", index=False, header=False)\n",
    "print(f\"Saved to '{neg_chipseq_bedfile_nonoverlap_filtered}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_fasta = \"hg19.fa\"\n",
    "\n",
    "neg_chipseq_bedfile_nonoverlap_filtered_fasta = chipseq_utils.add_str_before_suffixes(\n",
    "    neg_chipseq_bedfile_nonoverlap_filtered, \"_hg19\"\n",
    ").with_suffix(\".fa\")\n",
    "neg_chipseq_bedfile_nonoverlap_filtered_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = chipseq_utils.bedtools_getfasta(\n",
    "    input_fasta=reference_fasta,\n",
    "    output_fasta=neg_chipseq_bedfile_nonoverlap_filtered_fasta,\n",
    "    bed_file=neg_chipseq_bedfile_nonoverlap_filtered,\n",
    "    force_strandedness=True,\n",
    ")\n",
    "print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load sequences\n",
    "descriptions, sequences = chipseq_utils.parse_fasta(\n",
    "    neg_chipseq_bedfile_nonoverlap_filtered_fasta\n",
    ")\n",
    "\n",
    "# filter out nonsense\n",
    "nonsense = chipseq_utils.get_nonsense_sequence_mask(sequences, nonsense_letters=\"N\")\n",
    "print(f\"Found {nonsense.sum()} sequences with nonsense letters\")\n",
    "descriptions = descriptions[~nonsense]\n",
    "sequences = sequences[~nonsense]\n",
    "\n",
    "# one-hot encode\n",
    "sequences_onehot = chipseq_utils.one_hot(sequences)\n",
    "print(\"Shape of one-hot encoded data:\", sequences_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that GC are in slices 1:3 of the one-hot encoded data.\n",
    "# shape of this is (n_sequences,)\n",
    "gc_content_pos = sequences_onehot[:, :, 1:3].any(-1).mean(1)\n",
    "\n",
    "plt.hist(gc_content_pos, bins=25, range=(0, 1))\n",
    "plt.title(\"Histogram of GC content among positive sequences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYKAF6ZKY-7f"
   },
   "outputs": [],
   "source": [
    "# try to match positives and negatives by GC content.\n",
    "# use the one-hot encoded array.\n",
    "# we have to downsample negative peaks.\n",
    "#\n",
    "# do this after filtering with bedtools interset.\n",
    "#\n",
    "# then try to balance dataset. how much downsampling of negative data?\n",
    "\n",
    "# also give labels of 0 or 1.\n",
    "\n",
    "# save to hdf5\n",
    "\n",
    "# and then train on a model, and look at saliency map.\n",
    "# CTCF dataset is niiiiice. use that. Saliency map should show CTCF nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/67645/how-to-resample-one-dataset-to-conform-to-the-distribution-of-another-dataset\n",
    "# https://stackoverflow.com/questions/41495240/how-to-sample-data-based-off-the-distribution-of-another-dataset-in-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(gc_content_neg, replace=False, p=gc_content_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = scipy.stats.kde.gaussian_kde(gc_content_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_chosen = np.random.choice(\n",
    "    gc_content_neg, size=gc_content_pos.shape, replace=False, p=kde(gc_content_neg)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jb9PV32YwO2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWN4seq7YwMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w2yu8AtYwJv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kovkE0vxYv63"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3S0dOJfUPcI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "how-to-chip-seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
