{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-match",
   "metadata": {
    "id": "becoming-match"
   },
   "outputs": [],
   "source": [
    "# format code with \"black\" formatter. optional\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-anchor",
   "metadata": {
    "id": "fewer-anchor"
   },
   "source": [
    "# recreate \"representation learning\" paper\n",
    "\n",
    "Koo PK, Eddy SR (2019). Representation learning of genomic sequence motifs with convolutional neural networks. _PLOS Computational Biology_ 15(12): e1007560. https://doi.org/10.1371/journal.pcbi.1007560\n",
    "\n",
    "Also at https://www.biorxiv.org/content/10.1101/362756v4.full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-curve",
   "metadata": {
    "id": "clinical-curve"
   },
   "source": [
    "## install python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-record",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5350,
     "status": "ok",
     "timestamp": 1612204356625,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "round-record",
    "outputId": "c65681a8-9bdd-4da8-8b59-710d4cc2467b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --no-cache-dir https://github.com/p-koo/tfomics/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-block",
   "metadata": {
    "id": "numerical-block"
   },
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-logistics",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2023,
     "status": "ok",
     "timestamp": 1612204413835,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "aggressive-logistics",
    "outputId": "ce166bb4-05e3-4f97-b58d-5197efffadb9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget --timestamping https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-mapping",
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1612204415906,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "assumed-mapping"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-chance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1612204417184,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "institutional-chance",
    "outputId": "6730a268-4869-4397-cf24-77fe8774606e"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"synthetic_dataset.h5\")\n",
    "with h5py.File(data_path, \"r\") as dataset:\n",
    "    x_train = dataset[\"X_train\"][:].astype(np.float32)\n",
    "    y_train = dataset[\"Y_train\"][:].astype(np.float32)\n",
    "    x_valid = dataset[\"X_valid\"][:].astype(np.float32)\n",
    "    y_valid = dataset[\"Y_valid\"][:].astype(np.int32)\n",
    "    x_test = dataset[\"X_test\"][:].astype(np.float32)\n",
    "    y_test = dataset[\"Y_test\"][:].astype(np.int32)\n",
    "\n",
    "x_train = x_train.transpose([0, 2, 1])\n",
    "x_valid = x_valid.transpose([0, 2, 1])\n",
    "x_test = x_test.transpose([0, 2, 1])\n",
    "\n",
    "N, L, A = x_train.shape\n",
    "print(f\"{N} sequences, {L} nts per sequence, {A} nts in alphabet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-purchase",
   "metadata": {
    "id": "activated-purchase"
   },
   "source": [
    "## Max-pooling influences ability to build hierarchical motif representations\n",
    "\n",
    ">The goal of this computational task is to simultaneously make 12 binary predictions for the presence or absence of each transcription factor motif in the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-dimension",
   "metadata": {
    "id": "tested-dimension"
   },
   "source": [
    "### make CNN models\n",
    "\n",
    "from methods > cnn models\n",
    "\n",
    ">All CNNs take as input a 1-dimensional one-hot-encoded sequence with 4 channels (one for each nucleotide: A, C, G, T), then processes the sequence with two convolutional layers, a fully-connected hidden layer, and a fully-connected output layer with 12 output neurons that have sigmoid activations for binary predictions. Each convolutional layer consists of a 1D cross-correlation operation, which calculates a running sum between convolution filters and the inputs to the layer, followed by batch normalization (Ioffe and Szegedy, 2015), which independently scales the features learned by each convolution filter, and a non-linear activation with a rectified linear unit (ReLU), which replaces negative values with zero.\n",
    ">\n",
    ">The first convolutional layer employs 30 filters each with a size of 19 and a stride of 1. The second convolutional layer employs 128 filters each with a size of 5 and a stride of 1. All convolutional layers incorporate zero-padding to achieve the same output length as the inputs. Each convolutional layer is followed by max-pooling with a window size and stride that are equal, unless otherwise stated. The product of the two max-pooling window sizes is equal to 100. Thus, if the first max-pooling layer has a window size of 2, then the second max-pooling window size is 50. This constraint ensures that the number of inputs to the fully-connected hidden layer is the same across all models. The fully-connected hidden layer employs 512 units with ReLU activations.\n",
    ">\n",
    ">Dropout (Srivastava et al, 2014), a common regularization technique for neural networks, is applied during training after each convolutional layer, with a dropout probability set to 0.1 for convolutional layers and 0.5 for fully-connected hidden layers. During training, we also employed L2-regularization with a strength equal to 1e-6. The parameters of each model were initialized according to (He et al, 2015), commonly known as He initialization.\n",
    ">\n",
    ">All models were trained with mini-batch stochastic gradient descent (mini-batch size of 100 sequences) for 100 epochs, updating the parameters after each mini-batch with Adam updates (Kingma and Ba, 2014), using recommended default parameters with a constant learning rate of 0.0003. Training was performed on a NVIDIA GTX Titan X Pascal graphical processing unit with acceleration provided by cuDNN libraries (Chetlur et al, 2014). All reported performance metrics and saliency logos are drawn strictly from the test set using the model parameters which yielded the lowest binary cross-entropy loss on the validation set, a technique known as early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-indonesian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1612204420504,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "varied-indonesian",
    "outputId": "5ad9a143-4428-4932-805f-1816e9ee453c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    pool1: int, pool2: int, n_classes: int = 12, batch_size: int = None\n",
    ") -> tfk.Sequential:\n",
    "    \"\"\"Return a Model object with two convolutional layers, a\n",
    "    fully-connected hidden layer, and output. Sigmoid activation is\n",
    "    applied to logits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pool1 : int\n",
    "        Size of pooling window in the max-pooling operation after the first\n",
    "        convolution.\n",
    "    pool2 : int\n",
    "        Size of pooling window in the max-pooling operation after the second\n",
    "        convolution.\n",
    "    n_classes : int\n",
    "        Number of output units.\n",
    "    batch_size : int\n",
    "        Batch size of input. If `None`, batch size can be variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Instance of `tf.keras.Sequential`. This model is not compiled.\n",
    "    \"\"\"\n",
    "    if pool1 * pool2 != 100:\n",
    "        raise ValueError(\"product of pool sizes must be 100\")\n",
    "    l2_reg = tfk.regularizers.l2(1e-6)\n",
    "    return tfk.Sequential(\n",
    "        [\n",
    "            tfkl.Input(shape=(L, A), batch_size=batch_size),\n",
    "            # layer 1\n",
    "            tfkl.Conv1D(\n",
    "                filters=30,\n",
    "                kernel_size=19,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=l2_reg,\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.MaxPool1D(pool_size=pool1, strides=pool1),\n",
    "            tfkl.Dropout(0.1),\n",
    "            # layer 2\n",
    "            tfkl.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=5,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=l2_reg,\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.MaxPool1D(pool_size=pool2, strides=pool2),\n",
    "            tfkl.Dropout(0.1),\n",
    "            # layer 3\n",
    "            tfkl.Flatten(),\n",
    "            tfkl.Dense(\n",
    "                units=512, activation=None, use_bias=None, kernel_regularizer=l2_reg\n",
    "            ),\n",
    "            tfkl.BatchNormalization(),\n",
    "            tfkl.Activation(tf.nn.relu),\n",
    "            tfkl.Dropout(0.5),\n",
    "            # layer 4 (output). do not use activation (ie linear activation) so we can inspect\n",
    "            # the logits later.\n",
    "            tfkl.Dense(\n",
    "                units=n_classes,\n",
    "                activation=None,\n",
    "                use_bias=True,\n",
    "                kernel_initializer=tfk.initializers.GlorotNormal(),\n",
    "                bias_initializer=tfk.initializers.Zeros(),\n",
    "                name=\"logits\",\n",
    "            ),\n",
    "            tfkl.Activation(tf.nn.sigmoid, name=\"predictions\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-leonard",
   "metadata": {
    "id": "adapted-leonard"
   },
   "source": [
    "### train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"models\")\n",
    "pool_pairs = [(1, 100), (2, 50), (4, 25), (10, 10), (25, 4), (50, 2), (100, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-discretion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559313,
     "status": "ok",
     "timestamp": 1612204982870,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "colonial-discretion",
    "outputId": "37533dc5-04b2-4f60-c8f9-1fa7dafaabe0"
   },
   "outputs": [],
   "source": [
    "for pool1, pool2 in pool_pairs:\n",
    "    print(f\"++ training model with pool sizes {pool1}, {pool2}\")\n",
    "    model = get_model(pool1=pool1, pool2=pool2)\n",
    "\n",
    "    metrics = [\n",
    "        tfk.metrics.AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        tfk.metrics.AUC(curve=\"PR\", name=\"aupr\"),  # precision-recall\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=tfk.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tfk.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tfk.callbacks.EarlyStopping(\n",
    "            monitor=\"val_aupr\",\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            restore_best_weights=False,\n",
    "        ),\n",
    "        tfk.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_aupr\",\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        ),\n",
    "    ]\n",
    "    # train\n",
    "    history: tfk.callbacks.History = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=100,\n",
    "        epochs=100,\n",
    "        shuffle=True,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "    # save\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    filepath = save_dir / f\"model-{pool1:03d}-{pool2:03d}.h5\"\n",
    "    model.save(filepath)\n",
    "    # cannot save directly with json standard lib because numpy datatypes\n",
    "    # will cause an error. pandas converts things for us.\n",
    "    df_hist = pd.DataFrame(history.history)\n",
    "    df_hist.to_json(filepath.with_suffix(\".json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PX0E1vw26Q-p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1612205081750,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "PX0E1vw26Q-p",
    "outputId": "af343159-b22a-44ae-a524-c24a71c06343"
   },
   "outputs": [],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-harvey",
   "metadata": {
    "id": "developed-harvey"
   },
   "source": [
    "### evaluate models\n",
    "\n",
    "End goal is to get percent matches with JASPAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download JASPAR database.\n",
    "!wget --timestamping https://www.dropbox.com/s/ha1sryrxfhx7ex7/JASPAR_CORE_2016_vertebrates.meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-basics",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145740,
     "status": "ok",
     "timestamp": 1612205282517,
     "user": {
      "displayName": "Jakub Kaczmarzyk",
      "photoUrl": "",
      "userId": "00715572159212236562"
     },
     "user_tz": 300
    },
    "id": "split-basics",
    "outputId": "692b5c65-9af4-47c4-e524-39fde6013602",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# only run this if tomtom program not found\n",
    "if command -v tomtom; then\n",
    "  echo \"tomtom program installed\"\n",
    "  exit\n",
    "fi\n",
    "mkdir meme-src\n",
    "cd meme-src\n",
    "curl -fL https://meme-suite.org/meme/meme-software/5.3.1/meme-5.3.1.tar.gz | tar xz --strip-components 1\n",
    "./configure --prefix=$HOME/meme --with-url=http://meme-suite.org --enable-build-libxml2 --enable-build-libxslt\n",
    "make\n",
    "make test\n",
    "make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add meme programs to PATH\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += f'{os.pathsep}{Path.home() / \"meme\" / \"bin\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tfomics\n",
    "import tfomics.impress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-bargain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Container for comparison between motifs and filters for one model.\n",
    "meme_entry = namedtuple(\n",
    "    \"meme_entry\",\n",
    "    \"match_fraction match_any filter_match filter_qvalue min_qvalue num_counts\",\n",
    ")\n",
    "\n",
    "outputs = {}\n",
    "\n",
    "for pool1, pool2 in pool_pairs:\n",
    "    print(\"\\n++++ evaluating cnn\", pool1, pool2)\n",
    "    # Load model.\n",
    "    model = tfk.models.load_model(save_dir / f\"model-{pool1:03d}-{pool2:03d}.h5\")\n",
    "    _ = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # layers: (0)conv -> (1)batchnorm -> (2)relu\n",
    "    W = tfomics.moana.filter_activations(\n",
    "        x_test=x_test, model=model, layer=2, window=20, threshold=0.5\n",
    "    )\n",
    "\n",
    "    # Create meme file\n",
    "    W_clipped = tfomics.moana.clip_filters(W, threshold=0.5, pad=3)\n",
    "    meme_file = save_dir / f\"filters-{pool1:03d}-{pool2:03d}.meme\"\n",
    "    tfomics.moana.meme_generate(W_clipped, output_file=meme_file, prefix=\"filter\")\n",
    "    print(\"++ saved motifs to\", meme_file)\n",
    "\n",
    "    # Use tomtom to determine which motifs our filters are similar to.\n",
    "    print(\"++ running tomtom\")\n",
    "    output_path = \"filters\"\n",
    "    jaspar_path = \"JASPAR_CORE_2016_vertebrates.meme\"\n",
    "    args = [\n",
    "        \"tomtom\",\n",
    "        \"-thresh\",\n",
    "        \"0.5\",\n",
    "        \"-dist\",\n",
    "        \"pearson\",\n",
    "        \"-evalue\",\n",
    "        \"-oc\",\n",
    "        output_path,\n",
    "        meme_file,\n",
    "        jaspar_path,\n",
    "    ]\n",
    "    ret = subprocess.run(args, check=True)\n",
    "\n",
    "    # See which motifs the filters are similar to.\n",
    "    num_filters = moana.count_meme_entries(meme_file)\n",
    "    out = evaluate.motif_comparison_synthetic_dataset(\n",
    "        Path(output_path) / \"tomtom.tsv\", num_filters=num_filters\n",
    "    )\n",
    "    # Save comparisons to dict.\n",
    "    outputs[f\"cnn-{pool1:03d}-{pool2:03d}\"] = meme_entry(*out)\n",
    "\n",
    "    # Plot logos with motif names.\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    tfomics.impress.plot_filters(W, fig, num_cols=6, names=filter_match, fontsize=14)\n",
    "    fig.suptitle(f\"filters - cnn {pool1} x {pool2}\")\n",
    "    plt.savefig(save_dir / f\"filter-logos-{pool1:03d}-{pool2:03d}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"match fractions\")\n",
    "for k, v in outputs.items():\n",
    "    print(f\"{k}: {v.match_fraction:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-meaning",
   "metadata": {},
   "source": [
    "## Sensitivity of motif representations to the number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-pillow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-worst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-olive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eligible-sphere",
   "metadata": {},
   "source": [
    "## Motif representations are not very sensitive to 1st layer filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-miami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-netscape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-hospital",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-liberty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-bread",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "earlier-costs",
   "metadata": {},
   "source": [
    "## Motif representations are affected by the ability to assemble whole motifs in deeper layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tfk.regularizers.l2(1e-6)\n",
    "cnn_50_2 = tfk.Sequential(\n",
    "    [\n",
    "        tfkl.Input(shape=(L, A)),\n",
    "        # layer 1\n",
    "        tfkl.Conv1D(\n",
    "            filters=30,\n",
    "            kernel_size=19,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            kernel_regularizer=l2_reg,\n",
    "        ),\n",
    "        tfkl.BatchNormalization(),\n",
    "        tfkl.Activation(tf.nn.relu),\n",
    "        tfkl.MaxPool1D(pool_size=50, strides=2),\n",
    "        tfkl.Dropout(0.1),\n",
    "        # layer 2\n",
    "        tfkl.Conv1D(\n",
    "            filters=128,\n",
    "            kernel_size=5,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            kernel_regularizer=l2_reg,\n",
    "        ),\n",
    "        tfkl.BatchNormalization(),\n",
    "        tfkl.Activation(tf.nn.relu),\n",
    "        tfkl.MaxPool1D(pool_size=50, strides=50),\n",
    "        tfkl.Dropout(0.1),\n",
    "        # layer 3\n",
    "        tfkl.Flatten(),\n",
    "        tfkl.Dense(\n",
    "            units=512, activation=None, use_bias=None, kernel_regularizer=l2_reg\n",
    "        ),\n",
    "        tfkl.BatchNormalization(),\n",
    "        tfkl.Activation(tf.nn.relu),\n",
    "        tfkl.Dropout(0.5),\n",
    "        # layer 4 (output). do not use activation (ie linear activation) so we can inspect\n",
    "        # the logits later.\n",
    "        tfkl.Dense(\n",
    "            units=12,\n",
    "            activation=None,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=tfk.initializers.GlorotNormal(),\n",
    "            bias_initializer=tfk.initializers.Zeros(),\n",
    "            name=\"logits\",\n",
    "        ),\n",
    "        tfkl.Activation(tf.nn.sigmoid, name=\"predictions\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-trade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-upset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-veteran",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "composite-cincinnati",
   "metadata": {},
   "source": [
    "## Distributed representations build whole motif representations in deeper layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-illinois",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-premiere",
   "metadata": {
    "id": "resistant-premiere"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-representation-learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
